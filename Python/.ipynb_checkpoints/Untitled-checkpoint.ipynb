{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b129bc66",
   "metadata": {},
   "source": [
    "# Kubernetes is a container management technology developed by Google  to manage containerized applications in different kind of environments such as physical, virtual(Virtual Machine), and cloud infrastructure.It is  also used to automate the deployment, scaling, and operations of the container-based applications across the cluster of nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7397b1f9",
   "metadata": {},
   "source": [
    "# Kubernetes is a container management technology used to automate the deployment, scaling, and operations of the container-based applications across the cluster of nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d059ca",
   "metadata": {},
   "source": [
    "# Container actually offer the perfact host for samll independent application like microservices.\n",
    "# MicroServices:- Micro Service is an architecture that allows the developers to develop and deploy services independently. Each service running has its own process and this achieves the lightweight model to support business applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44958496",
   "metadata": {},
   "source": [
    "# Kubernetes offer High Availablity or no downtime and Scalablity which means you can scale your application fast when you have more load on it and more users are trying to access it and same way you can easily scale it down when the load goes down,So it makes your application more flexible to adjust to the increasing or decreasing load.and last one is disaster recovery which basically means that if an infrastructure has some problem like data is lost or the server explode or something bad happens with the services center the infrastructure has to have some kind of machanism to back-up the data and to restore it to the latest state,So that application doesn't lose any data and the containerized application can run from the latest state after the recovery "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a57597",
   "metadata": {},
   "source": [
    "<img src=\"https://www.tutorialspoint.com/kubernetes/images/cluster_architecture.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88311872",
   "metadata": {},
   "source": [
    "# Cluster:- A Kubernetes cluster is a set of node machines for running containerized applications.\n",
    "# Node:-A node is a working machine in Kubernetes cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f15e88",
   "metadata": {},
   "source": [
    "# the kubernetes cluster is made up with at least one master node and then connected to it  a couple of worker nodes where each node has a kubelet process running on it and kubelet is actually a kubernetes process that makes it possible for the cluster to talk to each other  and  execute some tasks on those nodes like running application processes.The kubelet is the primary \"node agent\" that runs on each node.<br><br> Each worker node has containers of different applications deployed on it, so depending on how the workload is distributed you would have different number of docker containers running on worker nodes and worker nodes are where the actual work is happening, so in worker node  your applications are running so the question is what is running on masternode.<br><br> Master node actually runs several kubernetes processes that are absolutely necessary to run and manage the cluster properly one of such processes is an api server which also is a container, an api server is actually the entry point to the kubernetes cluster so this is the process which the different kubernetes clients will talk to like ui. if you're using kubernetes dashboard, if you're using some scripts and automating technologies and a command line tool so all of these will talk to the api server.<br><br> Another process that is running on master node is a controller manager, which basically keeps an overview of what's happening in the cluster whether something needs to be repaired or maybe if a container died and it needs to be restarted etc<br><br>And another one is <b>scheduler</b> which is basically responsible for scheduling containers on different nodes based on the workload and the available server resources on each node. another very important component of the whole cluster is an <b>etcd key value storage </b> which basically holds at  any time the current state of the  kubernetes cluster so it has all the  configuration data inside  and all the status data of each node and  each container inside of that node and  the backup and restore  is actually made from these  etcd snapshots because you can recover  the whole cluster state using that etcd  snapshot<br><br> And last but not least also a  very important component of kubernetes is virtual network,  virtual network actually  turns  all the nodes inside of a cluster into  one powerful machine that has the sum of  all the resources of individual nodes.<br><br>In production  environments usually you would have at  least two masters inside of your  kubernetes cluster but in more cases of  course you're going to have multiple  musters where if one muster node  is down the cluster continues to  function smoothly because you have other  masters available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf7d7c0",
   "metadata": {},
   "source": [
    "# Virtual Network == Create one unified machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7104f62",
   "metadata": {},
   "source": [
    "<img src=\"1.png\" width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abce91b",
   "metadata": {},
   "source": [
    "<img src=\"2.png\" width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed4e428",
   "metadata": {},
   "source": [
    "<img src=\"3.png\" width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850283b4",
   "metadata": {},
   "source": [
    "<img src=\"4.png\" width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44528f1",
   "metadata": {},
   "source": [
    "# Pod:- A pod is a smallest unit in kubernetes and also it is collection of containers and its store inside a node of a Kubernetes cluster. It is possible to create a pod with multiple containers inside it. For example, keeping a database container and data container in the same pod."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f2149e",
   "metadata": {},
   "source": [
    "# Each pod gets own ip address,which help to communicate with each others. This is the interal ip address obviously it's not the public ip address,so my application container cancommunicate with database using this ip address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70042f0e",
   "metadata": {},
   "source": [
    "# In kubernetes pod is ephemeral(temp) in nature, Suppose your application is interact with your database and some how your database pod got deleted,obesily in this situation kubernetes launch new pod but new ip address and problem is your application is perivious interact with ip address,so you go there inside application container and set the newly launch pod ip address.                                                  <br><br>beacuse of this another component of  kubernetes called service is used  so service is basically a static ip  address or permanent ip address that can  be attached to each pod.<br>so my  app will have its own service and  database pod will have its own service  and the good thing is that the life  cycles of service and the pod are not  connected so even if the pod dies  the service and its ip address will stay  so you don't have to change that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa70dd86",
   "metadata": {},
   "source": [
    "# If you want to  your  application to be accessible through a  browser then for this you would  have to create an external service so  external services a service that opens  the communication from external sources  but obviously you wouldn't want your  database to be open to the public  requests and for that you would create  something called an internal service so  this is a type of a service that you  specify when creating the services.<br><br> if you  notice the url of  the external service is  an http protocol with a node ip address  so of the node not the service and the  port number of the service which is  good for test purposes<br><br>   component of kubernetes   called ingress so instead of service the   request goes first to ingress and it   does the forwarding then to the service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d11d08",
   "metadata": {},
   "source": [
    "# What is Ingress?<br><br>An API object that manages external access to the services in a cluster.Ingress may provide load balancing,and name-based virtual hosting.OR Ingress exposes HTTP and HTTPS routes from outside the cluster to services within the cluster.<br><img src=\"https://banzaicloud.com/blog/k8s-ingress/ingress-fanout.png\" width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0136b7",
   "metadata": {},
   "source": [
    "# Configuration files are meant to be separated from the application even though it is not mandatory. All the sensitive information regarding your application must be stored and kept safe. The configurations are the particular bits of data like API keys, tokens, and other secrets.<br><br> ConfigMaps are used to provide configuration data in key-value pairs in K8s.<br><br>Secrets üîê are used to hold sensitive data like passwords or keys. In both of the scaniro pod is connected to the ConfigMap and Secrets file so pods can retrive the data whatever written inside this files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c14a0e5",
   "metadata": {},
   "source": [
    "# The kubectl command line tool lets you control Kubernetes clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7476f835",
   "metadata": {},
   "source": [
    "# you want your database data or Log data to be persisted reliably long  term  and the way you can do it in kubernetes  is using another component of kubernetes  called volumes  and how it works is that it basically  attaches a physical storage on a hard  drive to your pod and that storage could  be either on a local machine meaning on  the same server node where the pod is  running or it could be on a remote  storage meaning outside of the  kubernetes cluster "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09357ccf",
   "metadata": {},
   "source": [
    "# Kubernetes Deployment:-creating deployments you can specify how many replicas of pods you want and you can also scale up orscale down the number of replicas of pods.<br><br>Kubernetes StatefulSet:- A StatefulSet is the Kubernetes controller used to run the stateful application like databases as Pods in the Kubernetes cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c76656",
   "metadata": {},
   "source": [
    "# So far, we've been working exclusively with the CLI, but there's an easier and more useful way to do it: creating configuration files using kubernetes YAML.<br>Each configuration file has three parts.<br>1.metadata<br>2.specification<br>3.status<br>etcd holds at any time the current status of any kubernetes component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5f8852",
   "metadata": {},
   "source": [
    "# Minikube:- Mini cube  is is basically one node cluster where  the master processes and the worker  processes both run on one node and this  node will have a docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d44ce37",
   "metadata": {},
   "source": [
    "advantage of\n",
    "using\n",
    "configuration from secret or config\n",
    "because if you need the same information\n",
    "in 10 different applications you create\n",
    "it once and reference it 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b81dc36",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1995792041.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_264465/1995792041.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    cluster ip\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "deployment   replication controller, replicaset  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "buildx  docker multiarchitecutre  build kr skte \n",
    "docker attach \n",
    "\n",
    "\n",
    "github action \n",
    "gitops pipeline \n",
    "\n",
    "\n",
    "\n",
    "aws ec2\n",
    "security \n",
    "vpc subney \n",
    "\n",
    "\n",
    "cidr aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8eed7a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1835122709.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_264465/1835122709.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    peri i have done internship in mlops . aprt from this also done poc devops in mlgitops\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "peri i have done internship in mlops . aprt from this also done poc devops in mlgitops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "githubaction\n",
    "rout53  dnsmap\n",
    "s3 \n",
    "git command "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25c0dfd",
   "metadata": {},
   "source": [
    "# whatever deployment you make, if you want access this deployment from the ouside world then you make a service,and you mentioned the type of the services  Nodeport if you given the servvice type is Nodeport then ouside cluster user can connect with the help of port, if you skip every time just write port number from the user then you mention the service type is loadbalancer or loadbalncer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dbf184",
   "metadata": {},
   "source": [
    "# if you want my services is access within the cluster and not outside the cluster then you mention the type of the services is clusterip."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b85a8fa",
   "metadata": {},
   "source": [
    "# In linux based operation system like redhat, we have a package manager called yum basically is responsible for install, remove, upgrade software packages on an operating system.Same like that in kubernetes HELM is a package manager.<br>So basically HELM help you to manage kubernetes application with the help of HELM CHART(HELM CHART is the collection of the manifest files) which help you define,install and upgrade even the most complex kubernetes application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5a93c7",
   "metadata": {},
   "source": [
    "# Kubernetes uses manifests files in the form of .yaml to create, modify, and delete Kubernetes resources such as pods, deployments, services, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34873d04",
   "metadata": {},
   "source": [
    "# The most important change in Helm 3 is the removal of Tiller . The most important change in Helm 3 is the removal of Tiller. Tiller was the service that actually communicated with the Kubernetes API server to manage the Helm packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724531f8",
   "metadata": {},
   "source": [
    "# Node Affinity/Anti-Affinity is one way to set rules on which nodes are selected by the scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9450d9c9",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1024/1*17Zz6v0HWIzgiOzQYmO6lA.jpeg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261e39a8",
   "metadata": {},
   "source": [
    "# GitHub Actions is provied the facility to Automate, customize, and execute your software development workflows  in your repository with GitHub Actions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa11b0ad",
   "metadata": {},
   "source": [
    "# Git is software for tracking changes in any set of files.<br>GitHub, Inc. is a provider of Internet hosting for software development and version control using Git."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b4d446",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP) is a field of artificial intelligence (AI) that enables computers to analyze and understand human language, both written and spoken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bf5dd4",
   "metadata": {},
   "source": [
    "# A Kubernetes Deployment runs multiple replicas of your application and automatically replaces any Pods that fail or become unresponsive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c005f536",
   "metadata": {},
   "source": [
    "# Run os on the physical machine is callled Type-1 Hypervisior just like your windows.<br>type 2 hypervisors is  you  load os inside of an existing operating system that's already loaded in the hardware ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8871f7",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Hyperviseur.svg/400px-Hyperviseur.svg.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e167d49",
   "metadata": {},
   "source": [
    "# When you build docker images in intel based architecture machine then this image is not working on AMD based architecture machine,to overcome this issues we use Multi‚Äêarch build concept in docker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f155aa12",
   "metadata": {},
   "source": [
    "# There are two ways to use Docker to build a multiarch image: using docker manifest or using docker buildx."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989686c6",
   "metadata": {},
   "source": [
    "# Intel. Intel is the most popular and well-known maker of processors. Manufacturers like Dell, Apple, Samsung and HP all use Intel processors in their computers. Intel processors are the most stable and offer the best all-round performance. The current i3, i5 and i7 models represent entry, middle and high level hardware.<br>AMD. AMD is Intel‚Äôs biggest competitor, offering processors that are similar to Intel‚Äôs, but at a, for the most part, cheaper price. The majority of computer manufacturers, except for Apple, also offer products with AMD processors. AMD‚Äôs Athlon processors are budget models while Phenom and FX are mainstream and high level respectively.<br>ARM. ARM processors are generally used in smartphones, mobile devices and tablets. Apple‚Äôs iPhone and iPad; Samsung‚Äôs Galaxy line and HTC devices all use some form of ARM processor in their mobile devices. A rule of thumb is, if it doesn‚Äôt have AMD or Intel in the name, it‚Äôs most likely an ARM processor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52958f77",
   "metadata": {},
   "source": [
    "# Kubectl set image deployment myweb\n",
    "apache-webserver-php=vimal13/apache-webserver-ph\n",
    "p:st21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4b7705",
   "metadata": {},
   "source": [
    "<img src=\"https://1.bp.blogspot.com/-vTjbB8gUC2w/X5RrDL4bC0I/AAAAAAAAw7c/HWuaS3GqY6oCfKqQersZae2FpUSWQOT8gCLcBGAsYHQ/w627-h237/persistent-volume-bond.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf181f2",
   "metadata": {},
   "source": [
    "# A DaemonSet ensures that all eligible nodes run a copy of a Pod.<img src=\"https://miro.medium.com/max/993/1*2iUgGBUrG4EHz3VbJgAQWA.jpeg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb219b87",
   "metadata": {},
   "source": [
    "#  Docker Containers are the ready applications created from Docker Images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea2011b",
   "metadata": {},
   "source": [
    "# The kernal is nothing but a computer program which control everything in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af2b66b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource Isolation In Container (Docker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb4c5d6",
   "metadata": {},
   "source": [
    "# ---Namespace:- In a docker the namespace is provide the layer of isolation namespace limits what you can see. in a os a lot container is running so  how one cntainer is isolated from other containers.<br> ---Control Group:-Control groups limit an application to a specific set of resources. it limits how much resources you can use.<br>---Union file systems:-Docker image is made up of filesystems layered over each other making it very lightweight and fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4b1c8e",
   "metadata": {},
   "source": [
    "# A daemon (also known as background processes) is a Linux or UNIX program that runs in the background."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6576aa52",
   "metadata": {},
   "source": [
    "# Docker Host provides a complete environment to execute and run applications.<br><br>Docker Daemon listens to Docker API requests and manages Docker objects such as images, containers, networks and volumes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c0bee7",
   "metadata": {},
   "source": [
    "# Docker client interact with docker daemon that perform a creating and building the docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de04088a",
   "metadata": {},
   "source": [
    "<img src=\"https://k21academy.com/wp-content/uploads/2020/05/2020-05-12-16_37_26-PowerPoint-Slide-Show-Azure_AZ104_M01_Compute_ed1-1024x534.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152d15d0",
   "metadata": {},
   "source": [
    "# Docker Engine :- Docker Engine is the layer on which Docker runs. It is installed on the host machine. It‚Äôs a lightweight runtime and tooling that manages containers, images, builds, and more.docker engine allows you to develop ship and run applications using the some  components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef01f3f",
   "metadata": {},
   "source": [
    "# a) Server: It is the docker daemon called dockerd. It can create and manage docker images, i.e, Containers, networks.\n",
    "\n",
    "# b) Rest API: It is used to instruct docker daemon what to do.\n",
    "\n",
    "# c) Command Line Interface (CLI): It is a client that is used to enter docker commands.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e21a48",
   "metadata": {},
   "source": [
    "# Runlevels determine which programs can execute after the OS boots up.Runlevels are numbered from zero to six.Each has own specific work like runlevel 0 means shuts down the system and runlevel 6 means reboots the system to restart it.there are 7 runlevel all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a299d8f9",
   "metadata": {},
   "source": [
    "# init is parent of all Linux processes with PID or process ID of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4347aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 Stages of Linux Boot Process (Startup Sequence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd02c7ffa9c538f0bfb5740c89a215bcbde02033924243f3d233f0c9916449df403"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
